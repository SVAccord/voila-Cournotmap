{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Seek for conflicts in structures eqg passed\n",
    "'''\n",
    "# take care about param types\n",
    "# нужно получать структуру на вход по которой уже разбирать на подгруппы\n",
    "#\n",
    "\n",
    "import re\n",
    "#import functions_is as fis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string # for int2base\n",
    "\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "#from itertools import permutations\n",
    "import itertools\n",
    "#import timeit\n",
    "#import datetime\n",
    "import copy\n",
    "# Dependencies (webapp)\n",
    "#from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "#import io\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def listToString(list1):\n",
    "    return (''.join(map(str, list1)))\n",
    "def diversity_num(vec, dim):\n",
    "    # return num of different digits without nans\n",
    "    dvst = 0\n",
    "    for i in range(0, dim):\n",
    "        for j in range(0, len(vec)):\n",
    "            if vec[j] == i:\n",
    "                dvst += 1\n",
    "                break\n",
    "    return dvst\n",
    "def list_getsome(vec, positions):\n",
    "    list_n = []\n",
    "    for y in positions:\n",
    "        list_n.append(vec[y])\n",
    "    #print(\"lnf\", list_n)\n",
    "    return(list_n)\n",
    "def diversity_vec(vec, dim):\n",
    "    dvst = []\n",
    "    for i in range(0, dim):\n",
    "        for j in range(0, len(vec)):\n",
    "            if vec[j] == i:\n",
    "                dvst.append(i)\n",
    "                break\n",
    "    return dvst\n",
    "def checkinpattern_str(txt, pattern):\n",
    "    # get strings\n",
    "    # if work w list from begining will be faster\n",
    "    ltxt = txt.split()\n",
    "    stxt = set(ltxt)\n",
    "    return stxt.issubset(set(pattern))\n",
    "\n",
    "def checkinpattern_list(ltxt, lpattern):\n",
    "    # get lists\n",
    "    stxt = set(ltxt)\n",
    "    return stxt.issubset(set(lpattern))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return positions of extern () , begin from start\n",
    "def openshell(f_text_v, start):\n",
    "    '''return what shell contais'''\n",
    "    mark = start\n",
    "    Term1_r_brct_ind, Term1_l_brct_ind = 0, 0\n",
    "    Term1_r_brct_cnt, Term1_l_brct_cnt = 0, 0\n",
    "    while mark <= len(f_text_v): \n",
    "        if( (f_text_v[mark] == '(') and (Term1_l_brct_cnt == 0) ): \n",
    "            Term1_l_brct_ind = mark # to save pos of f l_bracket\n",
    "        if(f_text_v[mark] == '('): Term1_l_brct_cnt = Term1_l_brct_cnt + 1\n",
    "        if(f_text_v[mark] == ')'):\n",
    "            if(Term1_r_brct_cnt >= Term1_l_brct_cnt ): return(-1) # like ...)*()\n",
    "            Term1_r_brct_cnt = Term1_r_brct_cnt + 1\n",
    "            Term1_r_brct_ind = mark\n",
    "        if( (Term1_l_brct_cnt != 0) and (Term1_r_brct_cnt == Term1_l_brct_cnt) ): break\n",
    "        mark = mark + 1\n",
    "    if(Term1_l_brct_cnt != Term1_r_brct_cnt): return(-1)\n",
    "    else:\n",
    "        return(f_text_v[(Term1_l_brct_ind+1):Term1_r_brct_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def structdisassemble(stct):\n",
    "    los = []\n",
    "    # assume braket format input, like (a(bc)). Don't see how make it simple for l10, l11 and so on\n",
    "    for i in range(len(stct)):\n",
    "        if stct[i] == '(': \n",
    "            t = [s for s in list(openshell(stct, i))  if s.isalpha()]\n",
    "            los.append(t)\n",
    "    return los\n",
    "\n",
    "# don't think it is need to sort\n",
    "def l2sort(l2):\n",
    "    for i in range(0,len(l2)):\n",
    "        l2[i].sort()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the structure defined on set of examples can be realised \n",
    "# with incopmlete techniqe\n",
    "# блоки\n",
    "# 1. на основании структуры составление плана обрабоки групп\n",
    "# 2. применение функции проверки/склейки к подгруппам по схеме\n",
    "# адреса + функция дают разбиение на группы. На выход разбиение\n",
    "# как это зациклить?\n",
    "# ввожу размерность для адресов и для функции\n",
    "#def eqg_og(data_ini, structure):\n",
    "def eqg_groupcheck(data_ini, grouptoinvestigate):\n",
    "    #функция проверки\n",
    "    #составление карты Карно на основе таблицы и функции(разбиения)\n",
    "    # data_ini - dataframe\n",
    "    # grouptoinvestigate - names of columns to select\n",
    "    #print(data_ini)\n",
    "    #print(data_ini.columns)\n",
    "    #alphabet = ['l1', 'l2', 'l3', 'l4', 'l5']\n",
    "    alphabet = data_ini.columns\n",
    "    alphabet = list(alphabet)\n",
    "    alphabet.pop(len(alphabet)-1)\n",
    "\n",
    "#     grouptoinvestigate_p = []\n",
    "#     for i in range(0,len(grouptoinvestigate)):\n",
    "#         grouptoinvestigate_p.append(grouptoinvestigate[i] - 1)\n",
    "    #print(grouptoinvestigate)\n",
    "    \n",
    "    lnum = data_ini.shape[1]-1\n",
    "    #print(\"lnum = \", lnum)\n",
    "    #print(data_ini.columns[grouptoinvestigate])\n",
    "        \n",
    "    # w with data in pandas style\n",
    "    #data = np.array(data_ini.iloc[:,grouptoinvestigate_p])\n",
    "    fornames = copy.deepcopy(grouptoinvestigate)\n",
    "    #fornames = grouptoinvestigate\n",
    "    fornames.append('IR')\n",
    "    #print(fornames)\n",
    "    #print(grouptoinvestigate)\n",
    "    data = data_ini[fornames]\n",
    "    data_names = data.columns\n",
    "    data = np.array(data_ini[grouptoinvestigate])\n",
    "    #print(\"data \\n\", data)\n",
    "    #reminder_slave = list(set([i for i in range(data_ini.shape[1]-1)])-set(grouptoinvestigate_p))\n",
    "    reminder_slave = list(set(alphabet)-set(grouptoinvestigate))\n",
    "    #print(reminder_slave)\n",
    "    data_slave = np.array(data_ini[reminder_slave])\n",
    "    #print(\"2 \\n\", data_slave)\n",
    "    dataout = data\n",
    "    # let's input numpy. And outpput too\n",
    "    #data = data_ini\n",
    "#     for i in range(1,3):\n",
    "#         print(data[i, [i,i+1])\n",
    "\n",
    "    # w with data in numpy style\n",
    "    #dataout = data[:,grouptoinvestigate_p]\n",
    "    \n",
    "    # эта сортиовка нужна для вывода результатов в return.  \n",
    "    dataout = np.unique(dataout, axis=0)\n",
    "    \n",
    "    # нужно сигнализировать если были противоречивые строки\n",
    "    \n",
    "    #dataout = dataout[np.lexsort((dataout[:,0], dataout[:,1], dataout[:,2], dataout[:,3]))]\n",
    "    dataout = dataout[np.lexsort([dataout[:,i] for i in range(dataout.shape[1])])]\n",
    "   \n",
    "    \n",
    "    #from operator import itemgetter\n",
    "    #data1 = sorted(data1,key=itemgetter(0))\n",
    "    #print(\"data1: \\n\" ,dataout)\n",
    "    dim = 1+data.max()-data.min()\n",
    "    dim_slave = 1+data_slave.max()-data_slave.min()\n",
    "    #print('max', data.max())\n",
    "    print(\"dim = \", (data.max()-data.min())+1)\n",
    "    print(\"dim_slave = \", (data_slave.max()-data_slave.min())+1)\n",
    "    dim_f = 1+data_ini['IR'].max() - data_ini['IR'].min()\n",
    "    print('dim_f', dim_f)\n",
    "    if dim_f > dim and dim_f > dim_slave:\n",
    "        print(\"\\n OUT OF SCALE \\n\")\n",
    "    #print(\"K: \" ,data[:,lnum-1])\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    # all posible values of group numbers\n",
    "    lenumeration = [i for i in range(0,lnum)] \n",
    "\n",
    "    len_combinations = 0\n",
    "    for i in range(2,lnum):\n",
    "        lcombinations = list(combinations(range(1, lnum+1), i))\n",
    "        len_combinations += len(lcombinations)\n",
    "    numofgroup = len(grouptoinvestigate)\n",
    "    #print(numofgroup)\n",
    "    # form table K\n",
    "    #print(\"group of leaves investigated: \", grouptoinvestigate)#lcombinations_p[numberofvalue])\n",
    "    #print(\"\\n\")\n",
    "    tbl_k = np.empty((dim**numofgroup,dim_slave**(lnum-numofgroup)))\n",
    "    tbl_k.fill(np.nan)\n",
    "    colfilled = []\n",
    "    rowfilled = []\n",
    "    seen = set()\n",
    "    seen_row = set()\n",
    "\n",
    "    #enumeration_l_col = np.array(c1)\n",
    "    #enumeration_l_row = np.array(c2)\n",
    "    # fill table K from data string by sting (x)\n",
    "    for x in range(0,len(data)):\n",
    "        #print(data[x,lcombinations[j]])\n",
    "        # get coordinate in nondecimal representation of string\n",
    "        #print(data[x,lcombinations[numberofvalue]])\n",
    "        # get coordinate in nondecimal representation of column\n",
    "        \n",
    "        #reminder = list(set(lenumeration)-set(grouptoinvestigate_p))#lcombinations[numberofvalue])) \n",
    "        #print(data[x,reminder])\n",
    "        # need to place F value in Ktable to selected coordinates\n",
    "        c1 = \"\".join([str(xx) for xx in data[x,:]])#lcombinations[numberofvalue]]])\n",
    "        #print(c1)\n",
    "        c2 = \"\".join([str(xx) for xx in data_slave[x,:]])\n",
    "        #print(c2)\n",
    "        c1_t = int(c1[::-1], base = dim)\n",
    "        c2_t = int(c2[::-1], base = dim_slave)\n",
    "        #print(\"d\",c1_t)\n",
    "        #print(\"d\",c2_t)\n",
    "        tbl_k[c1_t, c2_t] = data_ini.iat[x,lnum]\n",
    "        # попутно можно записать все столбцы в которых есть значения, соотв. другие м.б. удал.\n",
    "        if c2_t not in seen:\n",
    "            seen.add(c2_t)\n",
    "            colfilled.append(c2_t) \n",
    "        if c1_t not in seen_row:\n",
    "            seen_row.add(c1_t)\n",
    "            rowfilled.append(c1_t) \n",
    "    #print(colfilled)\n",
    "\n",
    "    #print(rowfilled)\n",
    "    #print(tbl_k)\n",
    "    colfilled.sort()\n",
    "    #print(colfilled)\n",
    "\n",
    "    tbl_k_s = tbl_k[:,colfilled]\n",
    "    # del nan rows\n",
    "    # use rowfilled\n",
    "    rows_nan = np.all(np.isnan(tbl_k_s), axis = (1))\n",
    "    tbl_k_s = tbl_k_s[~rows_nan,:]\n",
    "    #print(tbl_k_s)\n",
    "\n",
    "    # отсортируй и конвертируй в нужную шкалу  colfilled\n",
    "    # +1 - convert number in range from 1, for table output\n",
    "    #colfilled = [i+1 for i in colfilled]\n",
    "    #colfilled.sort()\n",
    "\n",
    "    #print(colfilled)\n",
    "    #rowfilled = [i+1 for i in rowfilled]\n",
    "    rowfilled.sort()\n",
    "\n",
    "    colfilled = [np.base_repr(int(i), base=dim_slave) for i in colfilled]\n",
    "    colfilled.insert(0, 0)\n",
    "    colfilled = [\"{0:0>{1}}\".format(i, data_slave.shape[1])[::-1] for i in colfilled]\n",
    "    rowfilled = [np.base_repr(int(i), base=dim) for i in rowfilled]\n",
    "    rowfilled = [\"{0:0>{1}}\".format(i, lnum-data_slave.shape[1])[::-1] for i in rowfilled]\n",
    "    colfilled[0] = ''\n",
    "    # print(colfilled)\n",
    "    # print(rowfilled)\n",
    "    temp_k = np.hstack((np.array(rowfilled).reshape(len(tbl_k_s),1), tbl_k_s))\n",
    "    temp_k = np.vstack((np.array(colfilled).reshape(1,temp_k.shape[1]), temp_k))\n",
    "\n",
    "    # create numbers of str|col \n",
    "    numbers = [int(i) for i in range(1,len(tbl_k_s)+1)]\n",
    "    numbers.insert(0, \"\")\n",
    "    numbers_col = [int(i) for i in range(0,tbl_k_s.shape[1]+1)]\n",
    "    numbers_col.insert(0, \"\")\n",
    "    numbers_col[1] = ''\n",
    "    temp_k = np.hstack((np.array(numbers).reshape(len(temp_k),1), temp_k))\n",
    "    temp_k = np.vstack((np.array(numbers_col).reshape(1,temp_k.shape[1]), temp_k))\n",
    "    #print(tbl_k_s)\n",
    "    print(temp_k)\n",
    "\n",
    "    # for now it is necessary to analyze whether the given alphabet is enough\n",
    "    list_ind = [[i for i in range(tbl_k_s.shape[0])]]\n",
    "    #print(list_ind)\n",
    "    inigroup = 1\n",
    "\n",
    "    for r in range(tbl_k_s.shape[1]):\n",
    "        # to evade path dependance in table analysis - take r from end to begining\n",
    "\n",
    "        # select a column, from back because extend used further\n",
    "        # checklist - digits in curr col\n",
    "        #if len(set(tbl_k_s[:,r])) > 1:\n",
    "        if diversity_num(tbl_k_s[:,r], dim_f) > 1:\n",
    "            # if there is conflict of type 1 = more than 1 different digit in col\n",
    "            #checklist = tbl_k_s[:,r]\n",
    "            checklist = copy.deepcopy(tbl_k_s[:,r])\n",
    "            checklist_pos = 0\n",
    "            for z in range(len(list_ind)-1,-1,-1): \n",
    "                # select a range in list_ind\n",
    "                # rev list - это связано с тем что del удаляет с конца\n",
    "                # в этой версии это не нужно\n",
    "                ind_t = []\n",
    "                flag_del_inigroup = 0\n",
    "                nan_counted = 0\n",
    "                for w in range(dim_f):\n",
    "                    # search for every simbol in alphabet in column                      \n",
    "                    range_in_range = np.where(tbl_k_s[list_ind[z],r] == w)[0].tolist()\n",
    "                    #if r > 0 and len(range_in_range) and not nan_counted:\n",
    "                    if not inigroup and len(range_in_range) and not nan_counted:\n",
    "                        # inigroup for don't count nans when inigroup activated\n",
    "                        plus_na = np.argwhere(np.isnan(tbl_k_s[list_ind[z],r]))\n",
    "                        plus_na = list(itertools.chain(*plus_na))\n",
    "                        range_in_range = list(itertools.chain(*[range_in_range, plus_na]))\n",
    "                        nan_counted = 1\n",
    "                    if len(range_in_range):\n",
    "                        range_in_range = list_getsome(list_ind[z], range_in_range)\n",
    "                        checklist[range_in_range] = np.nan\n",
    "                        ind_t.append(range_in_range)        \n",
    "                        flag_del_inigroup = 1\n",
    "\n",
    "                if flag_del_inigroup:\n",
    "                    del list_ind[z]\n",
    "                    flag_del_inigroup = 0\n",
    "                    inigroup = 0\n",
    "                # sort list for further includes and dubles checking\n",
    "                for c in range(len(ind_t)):\n",
    "                    ind_t[c].sort()\n",
    "                list_ind.extend(ind_t)\n",
    "            # seek for opportunity to expand eqg by new digits\n",
    "            # checklist_pos - digits in checklist\n",
    "            if ~np.isnan(checklist).all():\n",
    "                # test if there are not nans\n",
    "                # каждую позицию из разнообразия нужно приклеить без противоречия\n",
    "                # берем доступные числа из групп столбца и расширяем группы по ним\n",
    "                checklist_pos = np.argwhere(~np.isnan(checklist))#[0].tolist()\n",
    "                checklist_pos = list(itertools.chain(*checklist_pos))                \n",
    "                # need to sort list_ind for groups with digits go first\n",
    "                zzt = 0\n",
    "                cnt_zzt = 0\n",
    "                while cnt_zzt < len(list_ind)-1:\n",
    "                    #if not len(set(tbl_k_s[list_ind[zzt],r])):\n",
    "                    if not diversity_num(tbl_k_s[list_ind[zzt],r], dim_f):\n",
    "                        #print(tbl_k_s[list_ind[zzt],r])\n",
    "                        #print(len(set(tbl_k_s[list_ind[zzt],r])))\n",
    "                        list_ind.append(list_ind[zzt])\n",
    "                        del list_ind[zzt]\n",
    "                    else: zzt += 1\n",
    "                    cnt_zzt += 1\n",
    "                for zz in range(len(list_ind)):\n",
    "                    ind_tt = list_ind[zz]\n",
    "                    cnt_j = 0 \n",
    "                    for j in checklist[checklist_pos]:\n",
    "                        j = int(j)\n",
    "                        ldiv = diversity_vec(tbl_k_s[ind_tt,r], dim_f)\n",
    "                        # проверка ГЭ на наличие символа отличного от того для которого мы ищем группу                           \n",
    "                        # сформировать список без j и искать вхождение из ldiv в него\n",
    "                        list_without_j = [i for i in range(dim_f)]\n",
    "                        #print(\"dim\", dim)\n",
    "                        #print(\"j\", j)\n",
    "                        #print(list_without_j)\n",
    "                        del list_without_j[np.nonzero(np.array(list_without_j) == j)[0][0]]\n",
    "                        #print(list_without_j)\n",
    "                        if any(item in ldiv for item in list_without_j):\n",
    "                            cnt_j += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            list_ind[zz].append(checklist_pos[cnt_j])\n",
    "                            checklist[checklist_pos[cnt_j]] = np.nan\n",
    "                            checklist_pos = np.argwhere(~np.isnan(checklist))#[0].tolist()\n",
    "                            checklist_pos = list(itertools.chain(*checklist_pos))\n",
    "            #else # если в ГЭ нет номера из checklist, то добваить группу\n",
    "            # проверить остались ли свободные числа in checklist\n",
    "            if ~np.isnan(checklist).all():\n",
    "                # для каждого отдельного номинала своя группа\n",
    "                ldiv2 = diversity_vec(checklist, dim_f)\n",
    "                for i in ldiv2:\n",
    "                    range_in_range2 = np.where(checklist == i)[0].tolist()\n",
    "                    list_ind.append(range_in_range2)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    list_ind_output = copy.deepcopy(list_ind)\n",
    "    for i in range(len(list_ind_output)):\n",
    "        for j in range(len(list_ind_output[i])):\n",
    "            list_ind_output[i][j] += 1\n",
    "    #print(\"final partition: \", list_ind_output)   \n",
    "    #print(\"groups found = \", len(list_ind_output))\n",
    "    #del list_ind_output\n",
    "\n",
    "    #postanalisys: check if result may be merged for each pair of groups\n",
    "    q = 0\n",
    "    while q <= len(list_ind)-2:\n",
    "        flag_onse = 1\n",
    "        u = q + 1\n",
    "        while u <= len(list_ind)-1:\n",
    "            tbl_merged = np.vstack((tbl_k_s[list_ind[q],:], tbl_k_s[list_ind[u],:]))\n",
    "            #print(tbl_merged)\n",
    "            for p in range(tbl_merged.shape[1]):\n",
    "                if len(set(tbl_merged[~np.isnan(tbl_merged[:,p]),p])) > 1:\n",
    "                    break           \n",
    "                if p == tbl_merged.shape[1]-1:\n",
    "                    # was no break till ther end, so found 2 groups that can be merged\n",
    "                    if flag_onse:\n",
    "                        #print(\"in result of postanalysis found opportunity for merge\")\n",
    "                        flag_onse = 0\n",
    "                    #print(list_ind[q], list_ind[u])\n",
    "                    #t = list(itertools.chain(*[list_ind[q], list_ind[u]]))\n",
    "                    list_ind.append(list(itertools.chain(*[list_ind[q], list_ind[u]])))\n",
    "                    del list_ind[q]\n",
    "                    del list_ind[u-1]\n",
    "                    #list_ind.append(t)\n",
    "                    list_ind_output = copy.deepcopy(list_ind)\n",
    "                    for i in range(len(list_ind_output)):\n",
    "                        for j in range(len(list_ind_output[i])):\n",
    "                            list_ind_output[i][j] += 1\n",
    "                    #print(\"final partition: \", list_ind_output)   \n",
    "                    #print(\"groups found = \", len(list_ind_output))\n",
    "                    #print(\"\\n\")\n",
    "            u += 1\n",
    "        q += 1\n",
    "    #print(rowfilled)\n",
    "    l_eqg = [0 for i in range(len(rowfilled))]\n",
    "    cnt = 0\n",
    "    for i in list_ind:\n",
    "        for j in i:\n",
    "            l_eqg[j] = cnt\n",
    "        cnt += 1\n",
    "    #print(l_eqg)\n",
    "    #return pd.DataFrame({'A':data, 'B':l_eqg})\n",
    "    #temp_k = np.hstack((np.array(rowfilled).reshape(len(tbl_k_s),1), tbl_k_s))\n",
    "    dataout = np.hstack((dataout, np.array(l_eqg).reshape(len(dataout),1)))\n",
    "    #data_names = list(data_names)\n",
    "    #data_names = data_names.append('IS')\n",
    "    #print(data_names)\n",
    "    return pd.DataFrame(dataout, columns = data_names)\n",
    "    #return dataout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eceff4642c9499c9a62943a2a6c9cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8595a3e3eb504cc0935355fc06cb30c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91fe8ea5a7b4235b3e127fdfbeb52d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize outputs\n",
    "# Upload file and Upload button\n",
    "upload_btn_output = widgets.Output(clear_output=True)\n",
    "display(upload_btn_output)\n",
    "\n",
    "data_process_output = widgets.Output(clear_output=True)\n",
    "display(data_process_output)\n",
    "\n",
    "#Print out filtered\n",
    "data_output = widgets.Output(clear_output=True)\n",
    "display(data_output)\n",
    "\n",
    "\n",
    "#Event handler for upload button\n",
    "# можно загрузить свою таблицу из файла, вызов загрузки по кнопке просто ее перезапишет\n",
    "\n",
    "def upload_btn_eventhandler(obj):\n",
    "\n",
    "    #Read file\n",
    "    for file_name in upload_file.value:\n",
    "        \n",
    "        #Split file name to extract data\n",
    "        extension = file_name.split('.')[1]\n",
    "        content = upload_file.value[file_name]['content']\n",
    "\n",
    "        if(extension == 'xlsx' or extension == 'xls'):\n",
    "            data_ini = pd.read_excel(BytesIO(content))\n",
    "            \n",
    "        elif(extension == 'csv'):\n",
    "            data_ini = pd.read_csv(BytesIO(content), sep = ';')\n",
    "        \n",
    "        else:\n",
    "            print(\"File not accepted\")\n",
    "            \n",
    "        # Get indexes where value is > 1000\n",
    "        #data = data[data.amount < 1000]\n",
    "\n",
    "        with data_process_output:\n",
    "            print(f\"Processed a total of {len(data_ini)} transactions.\")\n",
    "            \n",
    "    tablenames = list(string.ascii_lowercase[0:(data_ini.shape[1]-1)])\n",
    "    tablenames.append('IR')\n",
    "    #print(tablenames)\n",
    "    data_ini.columns = tablenames\n",
    "    los = structdisassemble('((ab)cde)') \n",
    "    l2sort(los)\n",
    "    \n",
    "    ldf = []\n",
    "    ldf.append(data_ini)\n",
    "    #dict_losldf\n",
    "    dflosldf = pd.DataFrame(\n",
    "        {\n",
    "            \"group\": np.array(len(los), dtype=\"str\"),\n",
    "            \"dfadr\": np.empty(len(los), dtype=\"int32\"),\n",
    "            \"crash\": np.array(len(los), dtype=\"str\"),\n",
    "        }\n",
    "    )\n",
    "    cnt = 0\n",
    "    for i in range(len(los)):\n",
    "        dflosldf.iat[cnt,0] = ''.join(map(str, los[i]))\n",
    "        dflosldf.iat[cnt,1] = 0\n",
    "        dflosldf.iat[cnt,2] = \"\"\n",
    "        #print(\"dfnumofisg[i] \", dfnumofisg.iloc[cnt,:])\n",
    "        cnt += 1\n",
    "    dflosldf\n",
    "\n",
    "    alphabet = data_ini.columns\n",
    "    alphabet = list(alphabet)\n",
    "    alphabet.pop(len(alphabet)-1)\n",
    "\n",
    "    # need to add protection for data and structure compatibility\n",
    "    # what should be in result?\n",
    "    # if out of scale - to show where\n",
    "    # if all ok - output F or groups for each step\n",
    "\n",
    "    # нужна структура запускка вторичных функций. Вторичная функция должна знать на основе каких данных работать\n",
    "    # просто таблица с los[1]... во второй колонке адрес таблицы по которой нужно работать.\n",
    "    # при выборе los[т] - ищется ее вхождение в верхние строки. Строка вхождения - данные для работы.\n",
    "    for i in range(1,len(los)):\n",
    "        foundindex = i - 1 \n",
    "        if i == 1:\n",
    "            print('data used: \\n', ldf[i-1])\n",
    "            with data_output:\n",
    "                display(ldf[i-1])\n",
    "            print('group used: \\n', los[i])\n",
    "            print('group used: \\n', los[i])\n",
    "            ldf.append(eqg_groupcheck(ldf[i-1], los[i]))\n",
    "            dflosldf.loc[dflosldf['group'] == ''.join(map(str, los[i])),'dfadr'] = len(ldf)-1\n",
    "        else:\n",
    "            # seek for dfadr to w with\n",
    "            #print('['+str(''.join(map(str, los[i])))+']')\n",
    "            structlikeseries = pd.Series(los[i])\n",
    "            getrowslikesets = list(dflosldf['group'].apply(set))\n",
    "            rowscontainstructurebool = [structlikeseries.isin(x).all() for x in getrowslikesets]\n",
    "            rowscontainstructure = dflosldf['group'][rowscontainstructurebool]\n",
    "            structureindexes = list(rowscontainstructure.index) # def if empty list\n",
    "            structureindexes.pop() # remove last (self)\n",
    "            foundindex = structureindexes.pop() # return second from end   \n",
    "            #print('data used: \\n', ldf[foundindex])\n",
    "            with data_output:\n",
    "                display(ldf[foundindex])\n",
    "            print('group used: \\n', los[i])\n",
    "            ldf.append(eqg_groupcheck(ldf[foundindex], los[i]))\n",
    "            dflosldf.loc[dflosldf['group'] == ''.join(map(str, los[i])),'dfadr'] = len(ldf)-1\n",
    "        #print(dflosldf)\n",
    "        # anilize F dimension and break if it > scale\n",
    "\n",
    "        tcols = list(ldf[foundindex].columns)\n",
    "        tcols.pop()\n",
    "        with data_output:\n",
    "            display(\"IR: \\n\", ldf[len(ldf)-1][\"IR\"])\n",
    "        dim_adr =  max(ldf[len(ldf)-1].iloc[0:len(ldf[len(ldf)-1])-1, 0:ldf[len(ldf)-1].shape[1]-1].max())+1       \n",
    "        with data_output:\n",
    "            display(\"dim adr \", dim_adr) #max(ldf[len(ldf)-1][0:len(ldf)-2].max())+1) \n",
    "        dim_grp = ldf[len(ldf)-1][\"IR\"].max()+1\n",
    "        with data_output:\n",
    "            display(\"dim grp = \", dim_grp)\n",
    "        with data_output:\n",
    "            display('---------------')\n",
    "        if dim_grp > dim_adr:\n",
    "            with data_output:\n",
    "                display(\"\\n IR out of scale \\n\")\n",
    "                dflosldf.iat[i,2] = \"oos\"\n",
    "                display('------------------------------------------------')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data_ini\n",
    "\n",
    "# Buttons\n",
    "# Upload\n",
    "upload_file = widgets.FileUpload(multiple=False)\n",
    "upload_btn = widgets.Button(description=\"Upload\", icon='check', button_style='success')\n",
    "upload_btn.on_click(upload_btn_eventhandler)\n",
    "\n",
    "input_widgets = widgets.HBox([upload_file, upload_btn])\n",
    "with upload_btn_output:\n",
    "    display(input_widgets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_ini = pd.read_csv('210929_id_arctic_l5_data.csv', sep=';')\n",
    "#data_ini = pd.read_csv('210917_Id_RealEstate_DatawHeader.csv', sep=';')\n",
    "#data_ini = pd.read_csv('freeley_tab_d4_cl_h.csv', sep=';')\n",
    "#data_ini = pd.read_csv('210805_postcode35_data_l6.csv', sep=';')\n",
    "\n",
    "\n",
    "# tablenames = list(string.ascii_lowercase[0:(data_ini.shape[1]-1)])\n",
    "# tablenames.append('IR')\n",
    "# data_ini.columns = tablenames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psy structures\n",
    "# los = structdisassemble('((a((bc)(de)))(i((gh)(fj))))') \n",
    "# test5: M1\tl1\tM2\tl3\tM3\tl4\tM4\tM5\tl2\tM6\tl6\tl7\tM7\tl8\tM8\tl10\tM9\tl5\tl9\n",
    "#los = structdisassemble('(a(c(d((b(fg))(h(j(ei)))))))') \n",
    "# rs structures\n",
    "# M1l3M2l4M3l5M4l1l2\n",
    "#los = structdisassemble('(c(d(e(ab))))') \n",
    "# arct structures\n",
    "#los = structdisassemble('(a(b(c(de))))') \n",
    "\n",
    "\n",
    "#los = structdisassemble('((ab)cde)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data used: \n",
      "     a  b  c  d  e  IR\n",
      "0   2  1  1  2  0   2\n",
      "1   1  0  0  1  0   1\n",
      "2   1  1  2  0  2   2\n",
      "3   2  1  2  2  1   2\n",
      "4   1  1  0  1  1   2\n",
      "5   1  1  1  1  1   2\n",
      "6   2  2  2  1  1   2\n",
      "7   2  2  2  2  2   2\n",
      "8   1  2  1  2  1   1\n",
      "9   1  0  1  1  0   1\n",
      "10  0  1  1  2  1   1\n",
      "11  2  2  1  2  1   2\n",
      "12  2  0  1  1  1   2\n",
      "13  2  2  1  1  0   2\n",
      "14  2  2  2  2  1   2\n",
      "15  1  1  2  1  1   2\n",
      "16  0  1  1  1  1   2\n",
      "17  0  0  0  1  0   1\n",
      "18  2  1  1  0  0   1\n",
      "19  0  1  0  1  0   2\n",
      "20  2  0  0  2  1   2\n",
      "21  2  1  1  1  1   2\n",
      "22  1  1  2  0  1   1\n",
      "23  2  0  0  0  0   1\n",
      "24  1  1  0  2  2   2\n",
      "25  1  0  0  1  1   1\n",
      "26  1  0  1  2  0   1\n",
      "27  1  1  1  2  1   1\n",
      "28  0  0  1  0  0   0\n",
      "29  1  0  0  0  0   1\n",
      "30  1  1  1  0  1   1\n",
      "group used: \n",
      " ['a', 'b']\n",
      "dim =  3\n",
      "dim_slave =  3\n",
      "dim_f 3\n",
      "[['' '' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      "  '16']\n",
      " ['' '' '000' '100' '010' '110' '210' '101' '201' '011' '111' '211' '021'\n",
      "  '121' '221' '202' '022' '222']\n",
      " ['1' '00' 'nan' '1.0' '0.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['2' '10' '1.0' '1.0' 'nan' '1.0' '1.0' '1.0' 'nan' 'nan' 'nan' 'nan'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['3' '20' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' '2.0' 'nan'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['4' '01' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' '1.0'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['5' '11' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan' '1.0' '2.0' '1.0'\n",
      "  '1.0' '2.0' 'nan' '2.0' '2.0' 'nan']\n",
      " ['6' '21' 'nan' 'nan' '1.0' 'nan' '2.0' 'nan' 'nan' 'nan' '2.0' 'nan'\n",
      "  'nan' 'nan' '2.0' 'nan' 'nan' 'nan']\n",
      " ['7' '12' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['8' '22' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0'\n",
      "  'nan' '2.0' '2.0' 'nan' 'nan' '2.0']]\n",
      "\n",
      "\n",
      "IR: \n",
      " 0    2\n",
      "1    2\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    1\n",
      "Name: IR, dtype: int64\n",
      "dim adr  3\n",
      "dim grp =  3\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# ldf = []\n",
    "# ldf.append(data_ini)\n",
    "# #dict_losldf\n",
    "# dflosldf = pd.DataFrame(\n",
    "#     {\n",
    "#         \"group\": np.array(len(los), dtype=\"str\"),\n",
    "#         \"dfadr\": np.empty(len(los), dtype=\"int32\"),\n",
    "#         \"crash\": np.array(len(los), dtype=\"str\"),\n",
    "#     }\n",
    "# )\n",
    "# cnt = 0\n",
    "# for i in range(len(los)):\n",
    "#     dflosldf.iat[cnt,0] = ''.join(map(str, los[i]))\n",
    "#     dflosldf.iat[cnt,1] = 0\n",
    "#     dflosldf.iat[cnt,2] = \"\"\n",
    "#     #print(\"dfnumofisg[i] \", dfnumofisg.iloc[cnt,:])\n",
    "#     cnt += 1\n",
    "# dflosldf\n",
    "\n",
    "# alphabet = data_ini.columns\n",
    "# alphabet = list(alphabet)\n",
    "# alphabet.pop(len(alphabet)-1)\n",
    "    \n",
    "# # need to add protection for data and structure compatibility\n",
    "# # what should be in result?\n",
    "# # if out of scale - to show where\n",
    "# # if all ok - output F or groups for each step\n",
    "\n",
    "# # нужна структура запускка вторичных функций. Вторичная функция должна знать на основе каких данных работать\n",
    "# # просто таблица с los[1]... во второй колонке адрес таблицы по которой нужно работать.\n",
    "# # при выборе los[т] - ищется ее вхождение в верхние строки. Строка вхождения - данные для работы.\n",
    "# for i in range(1,len(los)):\n",
    "#     foundindex = i - 1 \n",
    "#     if i == 1:\n",
    "#         print('data used: \\n', ldf[i-1])\n",
    "#         print('group used: \\n', los[i])\n",
    "#         ldf.append(eqg_groupcheck(ldf[i-1], los[i]))\n",
    "#         dflosldf.loc[dflosldf['group'] == ''.join(map(str, los[i])),'dfadr'] = len(ldf)-1\n",
    "#     else:\n",
    "#         # seek for dfadr to w with\n",
    "#         #print('['+str(''.join(map(str, los[i])))+']')\n",
    "#         structlikeseries = pd.Series(los[i])\n",
    "#         getrowslikesets = list(dflosldf['group'].apply(set))\n",
    "#         rowscontainstructurebool = [structlikeseries.isin(x).all() for x in getrowslikesets]\n",
    "#         rowscontainstructure = dflosldf['group'][rowscontainstructurebool]\n",
    "#         structureindexes = list(rowscontainstructure.index) # def if empty list\n",
    "#         structureindexes.pop() # remove last (self)\n",
    "#         foundindex = structureindexes.pop() # return second from end   \n",
    "#         print('data used: \\n', ldf[foundindex])\n",
    "#         print('group used: \\n', los[i])\n",
    "#         ldf.append(eqg_groupcheck(ldf[foundindex], los[i]))\n",
    "#         dflosldf.loc[dflosldf['group'] == ''.join(map(str, los[i])),'dfadr'] = len(ldf)-1\n",
    "#     #print(dflosldf)\n",
    "#     # anilize F dimension and break if it > scale\n",
    "    \n",
    "#     tcols = list(ldf[foundindex].columns)\n",
    "#     tcols.pop()\n",
    "#     #print('cols', tcols)\n",
    "#     print(\"IR: \\n\", ldf[len(ldf)-1][\"IR\"])\n",
    "#     #print(\"ldf slise \\n\", ldf[len(ldf)-1].iloc[0:len(ldf)-1, 0:ldf[len(ldf)-1].shape[1]-1])\n",
    "#     #print(\"tb\", ldf[len(ldf)-1].iloc[0:len(ldf[len(ldf)-1])-1, 0:ldf[len(ldf)-1].shape[1]-1])\n",
    "#     dim_adr =  max(ldf[len(ldf)-1].iloc[0:len(ldf[len(ldf)-1])-1, 0:ldf[len(ldf)-1].shape[1]-1].max())+1\n",
    "#     #print(ldf[len(ldf)-1].iloc[0:len(ldf[len(ldf)-1])-1, 0:ldf[len(ldf)-1].shape[1]-1].max())\n",
    "#     #print(max(ldf[len(ldf)-1].iloc[0:len(ldf[len(ldf)-1])-1, 0:ldf[len(ldf)-1].shape[1]-1].max()))\n",
    "#     print(\"dim adr \", dim_adr) #max(ldf[len(ldf)-1][0:len(ldf)-2].max())+1) \n",
    "#     #print(\"dim = \", max(ldf[len(ldf)-1].max())+1) \n",
    "#     dim_grp = ldf[len(ldf)-1][\"IR\"].max()+1\n",
    "#     print(\"dim grp = \", dim_grp)\n",
    "#     print('---------------')\n",
    "#     #if ldf[foundindex][\"IR\"].max() > max(ldf[foundindex][tcols].max()):\n",
    "#     if dim_grp > dim_adr:\n",
    "#         print(\"\\n IR out of scale \\n\")\n",
    "#         dflosldf.iat[i,2] = \"oos\"\n",
    "#         print('------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>dfadr</th>\n",
       "      <th>crash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcde</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  dfadr crash\n",
       "0  abcde      0      \n",
       "1     ab      1      "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output result\n",
    "#dflosldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['' '' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      "  '16' '17']\n",
      " ['' '' '000' '100' '010' '110' '210' '020' '120' '101' '011' '111' '211'\n",
      "  '021' '121' '221' '102' '122' '222']\n",
      " ['1' '00' 'nan' 'nan' '1.0' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['2' '10' '1.0' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' '2.0'\n",
      "  'nan' 'nan' 'nan' 'nan' 'nan' '2.0' 'nan']\n",
      " ['3' '20' '1.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      "  'nan' '2.0' 'nan' 'nan' 'nan' 'nan' 'nan']\n",
      " ['4' '01' '0.0' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '2.0'\n",
      "  'nan' 'nan' '1.0' 'nan' 'nan' 'nan' 'nan']\n",
      " ['5' '11' 'nan' 'nan' '1.0' 'nan' 'nan' '1.0' 'nan' '1.0' 'nan' '2.0'\n",
      "  'nan' 'nan' '1.0' '1.0' 'nan' 'nan' 'nan']\n",
      " ['6' '21' 'nan' '1.0' 'nan' 'nan' '2.0' 'nan' '2.0' 'nan' '2.0' '2.0'\n",
      "  'nan' 'nan' 'nan' '2.0' 'nan' 'nan' 'nan']\n",
      " ['7' '12' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' '1.0' 'nan' '2.0'\n",
      "  'nan' 'nan' 'nan' 'nan' '2.0' 'nan' 'nan']\n",
      " ['8' '22' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan' 'nan'\n",
      "  '2.0' 'nan' '2.0' '2.0' 'nan' 'nan' '2.0']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>eqg</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>000</td>\n",
       "      <td>100</td>\n",
       "      <td>010</td>\n",
       "      <td>110</td>\n",
       "      <td>210</td>\n",
       "      <td>020</td>\n",
       "      <td>120</td>\n",
       "      <td>101</td>\n",
       "      <td>011</td>\n",
       "      <td>111</td>\n",
       "      <td>211</td>\n",
       "      <td>021</td>\n",
       "      <td>121</td>\n",
       "      <td>221</td>\n",
       "      <td>102</td>\n",
       "      <td>122</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1 eqg    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
       "0               1    2    3    4    5    6    7    8    9   10   11   12   13   \n",
       "1             000  100  010  110  210  020  120  101  011  111  211  021  121   \n",
       "2  1  00   0              1    2                                                \n",
       "3  2  10   0    1         1                             1    2                  \n",
       "4  3  20   0    1                                                      2        \n",
       "5  4  01   1    0                                            2              1   \n",
       "6  5  11   1              1              1         1         2              1   \n",
       "7  6  21   2         1              2         2         2    2                  \n",
       "8  7  12   0                                       1         2                  \n",
       "9  8  22   0                                                      2         2   \n",
       "\n",
       "    15   16   17   18  \n",
       "0   14   15   16   17  \n",
       "1  221  102  122  222  \n",
       "2                      \n",
       "3              2       \n",
       "4                      \n",
       "5                      \n",
       "6    1                 \n",
       "7    2                 \n",
       "8         2            \n",
       "9    2              2  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some convertions for excel output\n",
    "# print(temp_k)\n",
    "# df = pd.DataFrame(temp_k)\n",
    "# df1 = df.replace('nan', ' ', regex=True) \n",
    "# df1 = df1.replace(\"\\.0\", '', regex=True) \n",
    "# df1.insert(2, \"eqg\", l_eqg, True)\n",
    "# df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
